name: Dutch Social Monitor â€” Daily Pipeline

on:
  schedule:
    # Runs every day at 06:00 UTC (08:00 Amsterdam time)
    - cron: "0 6 * * *"
  # Allow manual trigger from GitHub Actions UI
  workflow_dispatch:

jobs:
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Job 1: Scrape X (Twitter) for Dutch social topics
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  scrape:
    name: "ğŸ•·ï¸ Scrape Tweets"
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js 20
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"
          cache-dependency-path: scraper/package-lock.json

      - name: Install scraper dependencies
        working-directory: scraper
        run: npm ci

      - name: Install Playwright Chromium browser
        working-directory: scraper
        run: npx playwright install chromium --with-deps

      - name: Build TypeScript
        working-directory: scraper
        run: npm run build

      - name: Run scraper
        working-directory: scraper
        env:
          SUPABASE_URL:                ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY:   ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          X_AUTH_TOKEN:                ${{ secrets.X_AUTH_TOKEN }}
          X_CT0:                       ${{ secrets.X_CT0 }}
        run: npm start

      # Pass a signal to the next job via artifact
      - name: Signal scrape complete
        run: echo "scrape_done=true" > /tmp/scrape_signal.txt

      - name: Upload signal artifact
        uses: actions/upload-artifact@v4
        with:
          name: scrape-signal
          path: /tmp/scrape_signal.txt
          retention-days: 1

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Job 2: NLP Processing (runs after scrape)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  nlp_processing:
    name: "ğŸ§  NLP Analysis"
    runs-on: ubuntu-latest
    needs: scrape
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: nlp/requirements.txt

      - name: Install NLP dependencies
        working-directory: nlp
        run: pip install -r requirements.txt

      - name: Run NLP processor
        working-directory: nlp
        env:
          SUPABASE_URL:                ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY:   ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          HUGGINGFACE_API_KEY:         ${{ secrets.HUGGINGFACE_API_KEY }}
        run: python processor.py

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Job 3: Notify on failure
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  notify_on_failure:
    name: "ğŸš¨ Notify Failure"
    runs-on: ubuntu-latest
    needs: [scrape, nlp_processing]
    if: failure()

    steps:
      - name: Post failure to Slack (optional)
        # Replace webhook URL with your own Slack incoming webhook secret
        if: ${{ secrets.SLACK_WEBHOOK_URL != '' }}
        uses: slackapi/slack-github-action@v1.26.0
        with:
          payload: |
            {
              "text": "âŒ Dutch Social Monitor pipeline failed! Check: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK
